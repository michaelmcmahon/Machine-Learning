{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLUSTERING PROBLEMS\n",
    "Types \n",
    "\t- K-Means Clustering\n",
    "\t- Hierarchal Clustering \n",
    "\t- Density-based Clustering\n",
    "\t- Distribution-based Clustering\n",
    "\n",
    "Clustering does not have defined categories \n",
    "Unlike Classification which uses pre-defined categories\n",
    "Clustering is a form of unsupervised learning (no training step)\n",
    "  \n",
    "What: Group items based on measured similarity\n",
    "\t- Maximise Intragroup Similarity\n",
    "\t- Minimise Intergroup Similarity \n",
    "\n",
    "How: All users can be represented by using some features\n",
    "\t- Age\n",
    "\t- Location\n",
    "\t- Freq of usage for each topic\n",
    "User can then be represented by a point in N-Dimensional space\n",
    "Similarity is then represented by the distance between users\n",
    "\n",
    "Large Dataset -> Features are represent datapoints numerically -> Clustering algorithm \n",
    "Clustering and Classification can work together\n",
    "Clustering can provide training data for a Classifier \n",
    "\n",
    "CLUSTERING USING K-MEANS ALGORITHM \n",
    "(UNSUPERVISED)\n",
    "\n",
    "Example: Document Clustering around themes \n",
    "Represent Text using 'Term Frequency Representation'\n",
    "\n",
    "Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    "Weight the term frequency to account for word rarity \n",
    "Words which are not common differentiate doc - upgrade these words\n",
    "Words which are more common do not differentiate doc - downgrade these words\n",
    "WEIGHT = 1 / # docs the words appear in\n",
    "Results is that each document becomes an - A tuple of N numbers\n",
    "A tuple of N numbers -> A point in an N-Dimensional Hypercube\n",
    "\n",
    "K-Means divides data into K clusters where K is specified by the user (i.e. # of clusters)\n",
    "Start by initializing a set of points as the 'K Means' (Centeroids of the cluster)\n",
    "\t1. The user specifies the initial number of clutsers/means/centeroids\n",
    "\t2. Each data point is assigned to the cluster of the nearest Mean\n",
    "\t3. Find the new means/centroids of the clusters\n",
    "\t4. Rinse and Repeat until the means don't change anymore\n",
    "\n",
    "Large Dataset -> TF-IDF -> K-Means Clustering  \n",
    "\n",
    "DEMO\n",
    "https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
    "Implement K-Means Clustering on IMDB reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/pluralsight/sentiment labelled sentences/imdb_labelled.txt\",\"r\")as text_file:\n",
    "    lines = text_file.read().split('\\n')\n",
    "lines = [line.split(\"\\t\") for line in lines if len(line.split(\"\\t\"))==2 and line.split(\"\\t\")[1]!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = [line[0] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform each review into a tuple of numbers - word frequency TF-IDF\n",
    "#stop words gets rid of junk words such 'the' 'a' 'and' etc.\n",
    "# max and min can be changed for tuning\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')\n",
    "train_documents = tfidf_vectorizer.fit_transform(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 1901.607\n",
      "Iteration  1, inertia 965.607\n",
      "Iteration  2, inertia 962.818\n",
      "Iteration  3, inertia 962.496\n",
      "Iteration  4, inertia 962.461\n",
      "Converged at iteration 4: center shift 0.000000e+00 within tolerance 1.002596e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=3, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the K-Means clustering algorithm with the number of clusters set to 3\n",
    "# after runnning this ever document will be assigned to a cluster\n",
    "km = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 100, n_init = 1, verbose = True)\n",
    "km.fit(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This review is long overdue, since I consider A Tale of Two Sisters to be the single greatest film ever made.  ', '1']\n",
      "[\"I'll put this gem up against any movie in terms of screenplay, cinematography, acting, post-production, editing, directing, or any other aspect of film-making.  \", '1']\n",
      "['\" The structure of this film is easily the most tightly constructed in the history of cinema.  ', '1']\n",
      "['I can think of no other film where something vitally important occurs every other minute.  ', '1']\n"
     ]
    }
   ],
   "source": [
    "# now it will be necessary to examine each cluster to identify the themes of each cluster\n",
    "# so we now have a loop that prints out three reviews that have the label 0\n",
    "count=0\n",
    "for i in range(len(lines)):\n",
    "    if count>3:\n",
    "        break\n",
    "    if km.labels_[i]==0:\n",
    "        print(lines[i])\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
