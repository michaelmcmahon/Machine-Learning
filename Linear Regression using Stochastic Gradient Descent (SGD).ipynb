{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSION PROBLEMS\n",
    "Types \n",
    "\t- Linear Regression\n",
    "\t- Polynomial Regression\n",
    "\t- Non-Linear Regression\n",
    "\t\n",
    "A form of supervised learning - wherever you have a training step there it is supervised\n",
    "\t- Quant trading and Demand forecasting\n",
    "\t- Commuting some kind of continuous value\n",
    "\t- Quantifying the relationship between two different relationships\n",
    "\n",
    "Independent Variables (Input) -> Regression Function -> Dependent Variable (Output)\n",
    "\n",
    "JIT sales and input predictions\n",
    "Facial Feature Recognition \n",
    "The Capital Assets Pricing Model (CAPM) for pricing risky securities \n",
    "\n",
    "Ra = Rf + Bi (Rm-Rf)\n",
    "\n",
    "Ra = The expected return on the particular security\n",
    "Rf = the rate of return for a risk-free security \n",
    "Rm = the broad market's expected rate of return \n",
    "Bi = The volitivity of a security = A Measure of its Risk\n",
    "Use regression to find Bi\n",
    "\n",
    "Problem -> Features - > Training -> Test\n",
    "Problem = Compute a continuous value\n",
    "Features = The Independent Variable\n",
    "Training = Use training data to quantify the relationship between (dependent & independent) variables\n",
    "Test = Compute dependent output value given the independent variables\n",
    "\n",
    "Classification vs Regression\n",
    "Categorical output vs Continuous output\n",
    "Black Box vs Mathematical Function\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSION USING SOLASTIC GRADIENT DESCENT (SGD) \n",
    "(SUPERVISED)\n",
    "Numpy - > from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "Apply to a Beta of a Stock\n",
    "Stochastic Gradient Method (SGD)\n",
    "\n",
    "Output = f(Input)\n",
    "Dependent Vars = Function(Independent Vars)\n",
    "Regression starts by assuming a specific form for this function \n",
    "(Make an assumption as to what it should like)\n",
    "A Linear Function -> b0 + b1x1 + b2x2 + …..\n",
    "In Linear Regression the 'b's are constants\n",
    "Need to find the Constant using past data \n",
    "By using past data with both dependent and independent vars\n",
    "Then you can find dependent vars using constant and independent vars\n",
    "Constants are called co-efficient' s\n",
    "\n",
    "Ri = Rf + Bi(Rm - Rf)\n",
    "Rearrange Equation so it looks like Linear Regression \n",
    "Dependent Vars = Function(Independent Vars)\n",
    "Ri - Rf = Bi(Rm - Rf)\n",
    "This is the equation of line passing through an origin\n",
    "\n",
    "Error (delta between Bi and actual on a given day) called Residuals\n",
    "GOAL - Minimize the error for the training data -> Optimization Techniques\n",
    "Stochastic Gradient Descent (SGD)\n",
    "Squared value of the Error of all data points = Mean Squared Error = Measure Overall Error\n",
    "Then SGD -> Pick a point - find slope and move down -> repeat until reach a minimum \n",
    "This will then define the best fit line to minimize the errors\n",
    "Need to manually adjust the step size and number of iterations used\n",
    "\n",
    "The CAPM Model to find the Beta for Google stock\n",
    " E(RGOOG) = RF + βGOOG (E(RM) – RF)\n",
    "= 3.08% + 0.91 (12.24% – 3.08%)\n",
    "= 11.45%\n",
    "\n",
    "From <https://www.stock-analysis-on.net/NASDAQ/Company/Alphabet-Inc/DCF/CAPM> \n",
    "\t1. Download Historical monthly prices for Google and Nasdaq\n",
    "\t2. Convert the prices to Returns = # at start of month - # end of month\n",
    "        In data we can use Adj Close Price to find the return\n",
    "        Monthy Return = (New Price - Old Price)/Old Price\n",
    "        Google Returns -> Dependent Var \n",
    "        NASDAC Returns -> Independent Var (Overall Market)\n",
    "\t3. Compute the Risk Free Rate of Return using the yields of 5 year Treasury bonds\n",
    "        The Adj.Close column represents the yield %\n",
    "        Divide by 100 to computer the Yield\n",
    "\t4. Subtract the yields from both the Google and Nasdaq Returns\n",
    "\t5. Regress the adjusted Google returns against adjusted Nasdaq returns SGDRegressor from Scikit-Learn Package\n",
    " \n",
    " NOTE: The first month of data may be all zeros so remove this line to prevent errors in processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filename, tbond=False):\n",
    "    data=pd.read_csv(filename, sep=\",\", usecols=[0,6], names=['Date','Price'], header=0)\n",
    "    if tbond==False:\n",
    "        returns=np.array(data[\"Price\"][:-1], np.float)/np.array(data[\"Price\"][1:], np.float)-1\n",
    "        data[\"Returns\"]=np.append(returns, np.nan)\n",
    "    #If a treasury bond this returns the yield\n",
    "    if tbond==True:\n",
    "        data[\"Returns\"]=data[\"Price\"]/100\n",
    "    data.index=data[\"Date\"]\n",
    "    #Returns of a Stock\n",
    "    data = data[\"Returns\"][0:-1]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "googData = readFile('/pluralsight/shares/goog.csv')\n",
    "nasdaqData = readFile('/pluralsight/shares/nasdaq.csv')\n",
    "tbondData = readFile('/pluralsight/shares/tbond5yr.csv', tbond=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciate the SDGRegessor with step size (eta) and max iterations (n_iter)\n",
    "reg = SGDRegressor(eta0=0.1, max_iter=100000, fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.1,\n",
       "       fit_intercept=False, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=100000, n_iter=None, penalty='l2',\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Step: call the fit method \n",
    "reg.fit((nasdaqData-tbondData).values.reshape(-1,1),(googData-tbondData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00480805])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output the coeffecient \n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
